\section { Computer Vision }
	\subsection { The pinhole camera model }
		Cameras project 3-dimensional scenes onto a 2-dimensional plane - the image plane.
		The overall projection of a single point in space (given in a world copordinate system) to the image plane can be divided into two independent successive operations \cite[S.~50]{Szeliski2010}:
		
		\subsubsection{Extrinsic parameters}
		A camera's extrinsic parameters describe its position and pose relative to the world coordinate system. For a simple pinhole camera those parameters are given with 
		
		\begin{equation}
		\matr{C} = \begin{bmatrix}
					\matr{R}_{3\times 3} & T_{3\times 1}\\
					0_{1\times 3} & 1
					\end{bmatrix}_{4\times 4} = -\matr{R}^{-1}T = -\matr{R}^TT \, . 
		\end{equation}
		$\matr{R}_{3\times 3}$ is a rotation matrix that represents the camera's rotation relative to the world coordinate system and T is the position of the world coordinate system, given in the new, camera-centered coordinate system. 

		\subsection{Intrinsic parameters}
		A camera intrinsic parameters reflect its internal structure and depend on focal length $f_{2\times 1}$, size of the image sensor and the principal point $c_{2\times1}$ which is defined as the intersection of the camera's optical axis with the image plane, denoted in pixel coordinates. This point ideally corresponds with the image sensor's center but might be slightly offset because of small misalignments within the camera.
		
		All in all this results in the camera's intrinsic matrix
		\begin{equation}
		\matr{K} =	\begin{bmatrix}
			f_x & s & c_x & 0 \\
			0 & f_y & c_y & 0 \\
			0 & 0 & 1 & 0
			\end{bmatrix}.
		\end{equation}
		The factor $s$ encodes any possible skew that might be introduced through misalignments between the camera's sensor and its optical axis and can typically be set to $0$ without affecting the approximation of the camera model too much.
		
		\subsection{Combined model}
		Combined, the intrinsic and extrinsic matrices lead to a camera matrix \cite{Szeliski2010}:
		
		\begin{equation}
		\matr{P} = \begin{bmatrix}\matr{K} & 0\\\matr{0}^T & 1\end{bmatrix}
		\begin{bmatrix}\matr{R} & T\\\matr{0}^T & 1\end{bmatrix}
		\end{equation}
		
		which maps a point $p_w = \left(x_w, y_w, z_w, 1\right)$ given in world coordinates to screen coordinates and disparity $d$, $p_s = \left(x_s, y_s, 1, d\right)$.
		
		
	\subsection { Segmentierung }
		

	
\section { Machine Learning }

		
	In recent years, there has been steady progress in the performance of computing hardware and thus in the area of machine learning.
In this section the machine-learning techniques used in the work are briefly shown and explained.

	\subsection { Neuronale Netze }
	Artificial neural networks 	are modeled on the biological function of human nerve tracts.

		\subsubsection { Das Perzeptron }
		\begin{figure}
					\input{Ressourcen/simple_perceptron}
					\centering
			\caption{Structure of a simple multi layer perceptron with one hidden layer.}
		\end{figure}
		The perceptron is the simplest case of a neural network. It consists of at least two layers with any number of arithmetic units called neurons with the first and last layer playing a special role since they are connected to the "`outside"' and transfer data into and out of the network. The layers in between are called "`hidden layers"'.
		
		All neurons of one layer are fully connected to every neuron of the following layer via a weighted connection:
		
		Each arithmetic unit in layer $j$ takes the data $o_{j-1} = o_i$ from the preceding neurons and calculates a preliminary output value $net_j$ by multiplying each input with the corresponding weights $w_{ij}$:
		
		 \ref{eq:perceptron_simple}. 
		
		\begin{equation}
			\label{eq:perceptron_simple}
			\text{net}_j = \sum_{i=1}^{n} w_{ij} \cdot o_i + b \, . 
		\end{equation}
		
		The weights $w_{xy}$ and bias values $b_x$ are optimized in the training process to approximate the training data as close as possible and will not change after the training.
		
		
		The inputs for the next layer are then calculated by filtering the preliminary results through a non-linear activation function,
		
		\begin{equation}
		\label{eq:perceptron_act}
		o_j = \varphi\left(\text{net}_j\right) \, . 
		\end{equation}
		

		
		 
		\subsubsection { Aktivierungsfunktionen }
		Since the basic arithmetic operations in a neural network are linear in nature, an additional nonlinearity must be introduced in order to learn nonlinear correlations. 
For this purpose different activation functions $\varphi$ are used, some of which are explained in the following.\\

		
		\textbf{Schwellenwertfunktion}
		Die Schwellenwertfunktion ist die ursprüngliche Aktivierungsfunktion für das Perzeptron nach \cite{McCulloch1943} und besitzt lediglich $0$ und $1$ als mögliche Ausgangswerte. Sie ist mit dem Schwellenwert $\epsilon$ definiert zu 
		\begin{equation}
		\label{eq:acti_sw}
		o_j = \left\{
		\begin{array}{ll}
		1\text{, wenn } \text{net}_j > \epsilon \\
		0 \text{ sonst}\\
		\end{array}
		\right.
		\end{equation}
		\textbf{Sigmoid}
			Die Sigmoid-Funktion ist mit einem variablen Steigungsparameter $a$ definiert zu 
			\begin{equation}
			\varphi\left(\text{net}_j\right) = \frac{1}{1+\exp(-a \cdot \text{net}_j)}
			\end{equation}
			Sie wird häufig anstatt der Schwellenwertfunktion genutzt, da sie stetig differenzierbar und somit gut geeignet für häufig genutzte Trainingsverfahren wie Gradient Descend ist.\\
			\begin{figure}[ht]
				\centering
				\begin{tikzpicture}
				\begin{axis}[
				domain=-200:200,
				xmin=-10, xmax=10,
				ymin=-1.5, ymax=1.5,
				samples=401,
				axis y line=center,
				axis x line=middle,
				]
				\addplot+[mark=none] {1/(1 + exp(-x)};
				\end{axis}
				\end{tikzpicture}
				\caption{Die Sigmoid-Funktion begrenzt die Ausgangswerte wie auch die Schwellenwertfunktion auf den Bereich [0, 1].}
				\label{fig:sigmoid_plot}
			\end{figure}


		\textbf{ReLu}
		Die Rectifying linear unit (kurz: ReLu) ist eine weitere Form der Aktivierungsfunktion, die insbesondere in Deep Neural Networks und Convolutional Neural Networks eingesetzt wird. Sie ist definiert zu
		\begin{equation}
			\label{eq:relu_def}
			\varphi(\text{net}_j) = \max(\text{net}_j, 0)
		\end{equation}
		womit negative Werte abgeschnitten werden. Im Vergleich zur Schwellenwert- bzw. Sigmoidfunktion führen große Eingangswerte hier nicht zur Sättigung (und damit kleinem Gradienten), was insbesondere in Gradientenverfahren wie in Abschnitt \ref{sec:gradient-descend} von Vorteil ist. \\
		
		\begin{figure}[ht]
			\centering
		\begin{tikzpicture}
		\begin{axis}[
		domain=-200:200,
		xmin=-10, xmax=10,
		ymin=-10, ymax=10,
		samples=401,
		axis y line=center,
		axis x line=middle,
		]
		\addplot+[mark=none] {max(x, 0)};
		\end{axis}
		\end{tikzpicture}
		\caption{Durch die ReLu-Aktivierungsfunktion werden negative Werte abgeschnitten.}
		\label{fig:relu_plot}
		\end{figure}

	
	\subsection { Spezialfälle Neuronaler Netze}
		\subsubsection { Convolutional Neural Networks (CNN) }
		Convolutional neural networks (\abbrev{CNN}) are a special case of neural networks that are particularly suitable for processing higher-dimensional structures such as images or temporal sequences of data. 

		In a CNN, in addition to the "`dense"' or "`fully connected"' layers described above, additional layers are used that perform convolution operations on the data.

		Instead of a simple multiplication, each input tensor is convoluted with a matrix in each convolution layer.

		In the case of a 2D CNN, the input data is a 2D matrix and each convolution layer also contains several two-dimensional matrices, which are moved over the input matrix to calculate the output data. 

		
		\todo{Bild für Faltung}
		
		
		\subsubsection { Recurrent Neural Networks (RNN) }
		\subsubsection { Long Short Term Memory (LSTM) }
	
	\subsection { Trainingsmethoden }
		
		\subsubsection{Gradient Descend}
		\label{sec:gradient-descend}
		
		\subsubsection{ADAM}
		\todo{Link zum Paper ist in tensorflow source von adam optimizer zu finden}
		
	\subsection{ One Shot Learning - Siamesische Netze }
	Ein Problem der bisher gezeigten Machine Learning-Methoden ist, dass sehr viele Traningsdaten benötigt werden, um die Netze ausreichend zu trainieren. In Anwendungsfällen, in denen die Trainingsdaten erst in der Benutzerinteraktion zur Verfügung stehen, können jedoch häufig nicht ausreichend viele Daten gesammelt werden. 
	
	Ein klassischer Anwendungsfall für One Shot learning ist daher zum Beispiel die Gesichtserkennung in Anwendersoftware. Hier muss es möglich sein, mit wenigen Gesichtern als Vorlage ein Gesicht auf einem neuen Photo zuverlässig wiederzuerkennen. Gleichzeitig sollte es jeder Zeit möglich sein, neue Klassen hinzuzufügen oder alte Klassen zu entfernen. Auch hier ist ein klassisches Netzwerk mit einer festen Anzahl von Ausgangsneuronen - und damit Klassen - ungeeignet.

	\subsubsection{Funktionsprinzip}
		Siamesische Netze sind eine mögliche Lösung für beide genannten Probleme: Sie vergleichen zwei Eingangstensoren und errechnen aus diesen einen Ähnlichkeitsfaktor. Anhand dieses Faktors kann nach Vergleich des unbekannten Eingangs mit allen bekannten Klassen diejenige mit der höchsten Übereinstimmung (oder keine im Fall eines Negativbeispiels) gewählt werden.
		
	\subsubsection{Aufbau des Netzes}
	 Bei einem Siamesischen Netzwerk handelt es sich um ein zweistufiges Netz, bestehend aus zwei Faltungsnetzen mit identischen Gewichten in der ersten Stufe, deren Ergebnis-Vektoren in der zweiten Stufe durch ein zusammenfassendes mehrlagiges Perzeptron in einen einzelnen Ähnlichkeits-Wert umgerechnet werden.
	 Die Faltungsnetze dienen dabei der Dimensionsreduktion - sie reduzieren den Eingangstensor auf einen Festure-Vektor und komprimieren damit die zur Verfügung stehende Information \todo{weiter}
	 
	 
	 
	 \begin{figure}
	 	\centering
	 	\input{Ressourcen/siamese_network}
	 	\caption{Aufbau eines siamesischen Netzwerkes}
	 	\label{fig:siamesenetwork}
	 \end{figure}
	 
	 
	 \subsubsection{Training}
	 Aufgrund des zweistufigen Aufbaus kann auch das Training des Netzes in zwei Stufen erfolgen.
	 
	 \subsubsection{Kostenfunktion: Triplet Loss}
	 Da das Netzwerk \todo{weiter}
	 

	
	Hierfür kann ein Siamesisches Netzwerk (en.: siamese network) genutzt werden. 
	
\section { Anatomie der menschlichen Hand }
	Die Bewegungsfreiheit der einzelnen Handglieder unterliegt anatomischen Beschränkungen, die in der Posenschätzung nützlich sein können, um die Güte der Schätzung zu beurteilen und mit einem passenden Modell entsprechend verfeinern zu können \cite{Melax5222017}.
	
	\begin{figure}
		\centering
		\includegraphics[width=0.7\linewidth]{Ressourcen/malik2018_hand_model}
		\caption[Handmodell nach \cite{Malik2018b}]{In \cite{Malik2018b} wird ein Modell ähnlich dem oben stehenden (Quelle: \cite{Malik2018b}) genutzt, in dem die vollständige Handpose durch 21, bzw. 22 (Gelenk-) Koordinaten bestimmt ist.}
		\label{fig:malik2018handmodel}
	\end{figure}
	
	
	\subsection{title}
	
	
\section{Kameraparameter}
\subsection{Intrinsische Parameter}
Die intrinsischen Paramter einer Kamera sind definiert durch die Brennweite $f$, das Format des Bildsensors und 
\subsection{Extrinsische Parameter}
	