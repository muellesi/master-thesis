{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "pose_train_data_dir = r\"E:\\MasterDaten\\Datasets\\FHAD\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "b'E:\\\\MasterDaten\\\\Datasets\\\\FHAD\\\\Hand_pose_annotation_v1\\\\Subject_5\\\\toast_wine\\\\3\\\\skeleton.txt'\nb'E:\\\\MasterDaten\\\\Datasets\\\\FHAD\\\\Hand_pose_annotation_v1\\\\Subject_3\\\\take_letter_from_enveloppe\\\\1\\\\skeleton.txt'\nb'E:\\\\MasterDaten\\\\Datasets\\\\FHAD\\\\Hand_pose_annotation_v1\\\\Subject_6\\\\tear_paper\\\\1\\\\skeleton.txt'\nb'E:\\\\MasterDaten\\\\Datasets\\\\FHAD\\\\Hand_pose_annotation_v1\\\\Subject_2\\\\scratch_sponge\\\\1\\\\skeleton.txt'\nb'E:\\\\MasterDaten\\\\Datasets\\\\FHAD\\\\Hand_pose_annotation_v1\\\\Subject_3\\\\write\\\\3\\\\skeleton.txt'\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "list_ds = tf.data.Dataset.list_files(os.path.join(pose_train_data_dir,'*/skeleton.txt'))\n",
    "for f in list_ds.take(5):\n",
    "    print(f.numpy())\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def parse_skeleton(skeleton_data_line, file_path):\n",
    "    data_elems = tf.strings.split(skeleton_data_line, \" \")\n",
    "    return file_path, data_elems[0], tf.strings.to_number(data_elems[1:], out_type=tf.dtypes.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(<tf.Tensor: id=717, shape=(), dtype=string, numpy=b'E:/MasterDaten/Datasets/FHAD/Hand_pose_annotation_v1/Subject_1/charge_cell_phone/1/skeleton.txt'>, <tf.Tensor: id=718, shape=(), dtype=string, numpy=b'0000'>, <tf.Tensor: id=719, shape=(63,), dtype=float32, numpy=\narray([ 37.4739,  76.0712, 348.356 ,  32.5099,  64.3266, 339.0773,\n        35.5006,  16.1834, 401.3612,  40.1808,  34.2762, 412.9691,\n        43.7768,  52.4597, 417.1439,  47.0601,  67.0314, 423.2051,\n         7.4596,  51.6898, 389.6903,  -9.1929,  43.2894, 423.3356,\n       -16.5373,  33.5237, 448.5287,   8.367 ,  27.0099, 436.9117,\n       -11.5193,  34.9446, 462.9667, -28.2976,  45.3796, 466.0647,\n        25.9924,  31.0274, 459.7573,  12.739 ,  31.2294, 486.6702,\n        -4.6451,  35.2024, 502.7328,  37.3626,  38.9797, 458.534 ,\n        13.1163,  45.1006, 471.1297,  -7.6845,  49.4089, 484.3117,\n        34.9216,  66.9734, 452.8134,  17.1006,  72.8127, 455.8657,\n        -3.5018,  79.5218, 459.6773], dtype=float32)>)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# test:\n",
    "file_path = \"E:/MasterDaten/Datasets/FHAD/Hand_pose_annotation_v1/Subject_1/charge_cell_phone/1/skeleton.txt\"\n",
    "simple_skeleton_dataset = tf.data.TextLineDataset(file_path).map(lambda x: parse_skeleton(x, file_path))\n",
    "for skeleton in simple_skeleton_dataset.take(1):\n",
    "    print(skeleton)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def read_skeleton_file(file_path):\n",
    "    skeleton_vals = tf.data.TextLineDataset(file_path).map(lambda x: parse_skeleton(x, file_path))\n",
    "    return skeleton_vals"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(<tf.Tensor: id=289, shape=(), dtype=string, numpy=b'E:\\\\MasterDaten\\\\Datasets\\\\FHAD\\\\Hand_pose_annotation_v1\\\\Subject_1\\\\close_liquid_soap\\\\4\\\\skeleton.txt'>, <tf.Tensor: id=290, shape=(), dtype=string, numpy=b'0000'>, <tf.Tensor: id=291, shape=(63,), dtype=string, numpy=\narray([b'77.481400', b'-5.575300', b'331.042400', b'75.168800',\n       b'-10.791900', b'316.341700', b'67.812400', b'-83.710500',\n       b'345.233900', b'69.029900', b'-74.157300', b'365.014100',\n       b'70.715500', b'-60.745100', b'378.365900', b'71.898900',\n       b'-51.378600', b'391.431900', b'46.846500', b'-57.218700',\n       b'324.551400', b'38.594000', b'-89.737100', b'319.033000',\n       b'37.220200', b'-116.002400', b'309.428500', b'46.438100',\n       b'-114.970000', b'367.804500', b'31.388700', b'-136.979500',\n       b'383.696300', b'16.581200', b'-147.051600', b'392.600800',\n       b'45.207200', b'-108.452200', b'393.558100', b'29.891800',\n       b'-130.500200', b'411.908800', b'12.142400', b'-141.388200',\n       b'423.842300', b'51.338900', b'-91.273500', b'406.547500',\n       b'38.313900', b'-111.794700', b'425.491300', b'21.444100',\n       b'-125.889100', b'437.397500', b'59.880500', b'-72.381200',\n       b'417.459200', b'51.597100', b'-86.856800', b'435.398200',\n       b'37.128400', b'-97.580700', b'448.033700'], dtype=object)>)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "skeleton_data = list_ds.flat_map(read_skeleton_file)\n",
    "for skeleton in skeleton_data.take(1):\n",
    "    print(skeleton)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_corresponding_images(skeleton_path, frame_index, skeleton):\n",
    "    video_path = tf.strings.regex_replace(skeleton_path, \"Hand_pose_annotation_v1\", \"Video_files\")\n",
    "    path_length = tf.strings.length(video_path)\n",
    "    video_path = tf.strings.substr(video_path, 0, path_length - len(\"skeleton.txt\"))\n",
    "    path_add = tf.constant(\"depth/depth_\")\n",
    "    file_ending = tf.constant(\".png\")\n",
    "    img_path = tf.strings.join([video_path, path_add, frame_index, file_ending])\n",
    "    return skeleton_path, tf.io.decode_png(tf.io.read_file(img_path), dtype=tf.dtypes.uint16), skeleton\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "b'E:\\\\MasterDaten\\\\Datasets\\\\FHAD\\\\Hand_pose_annotation_v1\\\\Subject_4\\\\read_letter\\\\2\\\\skeleton.txt'\n\narray([[[0],\n        [0],\n        [0],\n        ...,\n        [0],\n        [0],\n        [0]],\n\n       [[0],\n        [0],\n        [0],\n        ...,\n        [0],\n        [0],\n        [0]],\n\n       [[0],\n        [0],\n        [0],\n        ...,\n        [0],\n        [0],\n        [0]],\n\n       ...,\n\n       [[0],\n        [0],\n        [0],\n        ...,\n        [0],\n        [0],\n        [0]],\n\n       [[0],\n        [0],\n        [0],\n        ...,\n        [0],\n        [0],\n        [0]],\n\n       [[0],\n        [0],\n        [0],\n        ...,\n        [0],\n        [0],\n        [0]]], dtype=uint16)\n\n[b'9.538700' b'23.072500' b'270.988000' b'-0.768100' b'21.468100'\n b'262.173500' b'-17.322400' b'-39.127200' b'292.217400' b'-2.153600'\n b'-32.258900' b'305.013400' b'10.991300' b'-24.877300' b'314.848100'\n b'23.990900' b'-13.010100' b'320.568000' b'-36.378900' b'2.157900'\n b'300.991300' b'-60.320500' b'-10.824600' b'327.089000' b'-67.226600'\n b'-20.130600' b'353.672900' b'-39.944300' b'-39.273200' b'328.668700'\n b'-54.485700' b'-39.367100' b'352.099700' b'-61.656500' b'-21.092200'\n b'359.557000' b'-26.163000' b'-30.925300' b'342.289800' b'-43.216700'\n b'-29.978100' b'368.766900' b'-55.721000' b'-16.124300' b'378.395800'\n b'-14.356800' b'-21.604800' b'347.700600' b'-32.550300' b'-19.256000'\n b'371.280400' b'-45.709500' b'-8.442800' b'383.565000' b'18.561600'\n b'-29.159700' b'356.181000' b'14.446100' b'-41.401600' b'383.176700'\n b'11.066400' b'-46.901000' b'399.979500']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "full_ds = skeleton_data.map(get_corresponding_images)\n",
    "for path, image_raw, skeleton in full_ds.take(1):\n",
    "    print(path.numpy())\n",
    "    print()\n",
    "    print(repr(image_raw.numpy()[:100]))\n",
    "    print()\n",
    "    print(skeleton.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}