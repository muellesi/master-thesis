% This file was created with Citavi 6.3.0.0

@proceedings{1317March2001,
 year = {13-17 March 2001},
 title = {{Proceedings IEEE Virtual Reality 2001}},
 publisher = {{IEEE Comput. Soc}},
 isbn = {0-7695-0948-7}
}


@proceedings{1317March2001b,
 year = {13-17 March 2001},
 title = {{Proceedings IEEE Virtual Reality 2001}},
 publisher = {{IEEE Comput. Soc}},
 isbn = {0-7695-0948-7}
}


@book{2006,
 year = {2006},
 title = {{Proceedings of the 5th international conference on devlopment and learning ICDL 2006: Indiana University, Bloomington, IN : May 31 - June 3rd, 2006}},
 address = {[Bloomington, Ind.]},
 publisher = {{Department of Psychological and Brain Sciences, Indiana University}},
 isbn = {9780978645601}
}


@proceedings{2013,
 year = {2013},
 title = {{Proceedings of the IEEE International Conference on Computer Vision (ICCV)}}
}


@proceedings{2014,
 year = {2014},
 title = {{2013 IEEE International Conference on Computer Vision: 1-8 December 2013}},
 keywords = {Computer vision},
 address = {New York},
 publisher = {IEEE},
 isbn = {978-1-4799-2840-8}
}


@proceedings{27.06.201630.06.2016,
 year = {27.06.2016 - 30.06.2016},
 title = {{2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}},
 publisher = {IEEE},
 isbn = {978-1-4673-8851-1}
}


@book{Cremers2015,
 year = {2015},
 title = {{Computer Vision -- ACCV 2014}},
 address = {Cham},
 publisher = {{Springer International Publishing}},
 isbn = {978-3-319-16864-7},
 series = {{Lecture Notes in Computer Science}},
 editor = {Cremers, Daniel und  Reid, Ian und  Saito, Hideo und  Yang, Ming-Hsuan},
 doi = {10.1007/978-3-319-16865-4}
}


@book{Cremers2015b,
 year = {2015},
 title = {{Computer Vision -- ACCV 2014}},
 address = {Cham},
 publisher = {{Springer International Publishing}},
 isbn = {978-3-319-16864-7},
 series = {{Lecture Notes in Computer Science}},
 editor = {Cremers, Daniel und  Reid, Ian und  Saito, Hideo und  Yang, Ming-Hsuan},
 doi = {10.1007/978-3-319-16865-4}
}


@article{DiWu2016,
 abstract = {This paper describes a novel method called Deep Dynamic Neural Networks (DDNN) for multimodal gesture recognition. A semi-supervised hierarchical dynamic framework based on a Hidden Markov Model (HMM) is proposed for simultaneous gesture segmentation and recognition where skeleton joint information, depth and RGB images, are the multimodal input observations. Unlike most traditional approaches that rely on the construction of complex handcrafted features, our approach learns high-level spatio-temporal representations using deep neural networks suited to the input modality: a Gaussian-Bernouilli Deep Belief Network (DBN) to handle skeletal dynamics, and a 3D Convolutional Neural Network (3DCNN) to manage and fuse batches of depth and RGB images. This is achieved through the modeling and learning of the emission probabilities of the HMM required to infer the gesture sequence. This purely data driven approach achieves a Jaccard index score of 0.81 in the ChaLearn LAP gesture spotting chal},
 author = {{Di Wu} und  Pigou, Lionel und  Kindermans, Pieter-Jan und  Le, Nam Do-Hoang und  Shao, Ling und  Dambre, Joni und  Odobez, Jean-Marc},
 year = {2016},
 title = {{Deep Dynamic Neural Networks for Multimodal Gesture Segmentation and Recognition}},
 keywords = {Algorithms;Gestures;Humans;Learning;Neural Networks (Computer);Normal Distribution;Pattern Recognition, Automated},
 pages = {1583--1597},
 volume = {38},
 number = {8},
 journal = {{IEEE transactions on pattern analysis and machine intelligence}},
 doi = {10.1109/TPAMI.2016.2537340}
}


@article{FeiFei,
 author = {Fei-Fei, Li},
 title = {{Knowledge transfer in learning to recognize visual objects classes}}
}


@book{Fitzgibbon2012,
 year = {2012},
 title = {{Computer vision - ECCV 2012: 12th European Conference on Computer Vision, Florence, Italy, October 7 - 13, 2012 ; proceedings, part VI}},
 keywords = {Artificial intelligence;Computer graphics;Computer science;Computer software;Computer vision;Optical pattern recognition},
 address = {Berlin},
 volume = {7577},
 publisher = {Springer},
 isbn = {978-3-642-33782-6},
 series = {{Lecture Notes in Computer Science}},
 editor = {Fitzgibbon, Andrew und  Lazebnik, Svetlana und  Perona, Pietro und  Sato, Yoichi und  Schmid, Cordelia},
 doi = {10.1007/978-3-642-33783-3}
}


@article{Ge2019,
 abstract = {In this paper, we present a novel method for real-time 3D hand pose estimation from single depth images using 3D Convolutional Neural Networks (CNNs). Image-based features extracted by 2D CNNs are not directly suitable for 3D hand pose estimation due to the lack of 3D spatial information. Our proposed 3D CNN-based method, taking a 3D volumetric representation of the hand depth image as input and extracting 3D features from the volumetric input, can capture the 3D spatial structure of the hand and accurately regress full 3D hand pose in a single pass. In order to make the 3D CNN robust to variations in hand sizes and global orientations, we perform 3D data augmentation on the training data. To further improve the estimation accuracy, we propose applying the 3D deep network architectures and leveraging the complete hand surface as intermediate supervision for learning 3D hand pose from depth images. Extensive experiments on three challenging datasets demonstrate that our proposed approac},
 author = {Ge, Liuhao und  Liang, Hui und  Yuan, Junsong und  Thalmann, Daniel},
 year = {2019},
 title = {{Real-Time 3D Hand Pose Estimation with 3D Convolutional Neural Networks}},
 pages = {956--970},
 volume = {41},
 number = {4},
 journal = {{IEEE transactions on pattern analysis and machine intelligence}},
 doi = {10.1109/TPAMI.2018.2827052}
}


@proceedings{Hoey2011,
 year = {2011},
 title = {{Proceedings of the British Machine Vision Conference 2011: BMVC 2011, the 22nd British Machine Vision Conference, University of Dundee, 29 August-2 September 2011}},
 address = {Durham},
 publisher = {{BMVA Press}},
 isbn = {1-901725-43-X},
 editor = {Hoey, Jesse},
 institution = {{British Machine Vision Conference} und  BMVC},
 doi = {10.5244/C.25}
}


@proceedings{IEEEConferenceonComputerVisionandPatternRecognition2016,
 year = {2016},
 title = {{29th IEEE Conference on Computer Vision and Pattern Recognition: CVPR 2016 : proceedings : 26 June-1 July 2016, Las Vegas, Nevada}},
 keywords = {Maschinelles Sehen;Mustererkennung},
 address = {Piscataway, NJ},
 publisher = {IEEE},
 isbn = {978-1-4673-8851-1},
 institution = {{IEEE Conference on Computer Vision and Pattern Recognition} und  {Institute of Electrical and Electronics Engineers} und  CVPR}
}


@proceedings{InstituteofElectricalandElectronicsEngineers2013,
 year = {2013},
 title = {{IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2013: 23 - 28 June 2013, Portland, Oregon, USA ; proceedings}},
 keywords = {Maschinelles Sehen;Mustererkennung},
 address = {Piscataway, NJ},
 publisher = {IEEE},
 isbn = {978-0-7695-4989-7},
 institution = {{Institute of Electrical and Electronics Engineers} und  {IEEE Computer Society} und  {IEEE Conference on Computer Vision and Pattern Recognition} und  CVPR}
}


@article{Jones2002,
 abstract = {The existence of large image datasets such as the set of photos on the World Wide Web make it

possible to build powerful generic models for low-level image attributes like color using simple histogram learning

techniques. We describe the construction of color models for skin and non-skin classes from a dataset of nearly

1 billion labelled pixels. These classes exhibit a surprising degree of separability which we exploit by building a skin

pixel detector achieving a detection rate of 80{\%} with 8.5{\%} false positives. We compare the performance of histogram

and mixture models in skin detection and ﬁnd histogram models to be superior in accuracy and computational cost.

Using aggregate features computed from the skin pixel detector we build a surprisingly effective detector for naked

people. Our results suggest that color can be a more powerful cue for detecting people in unconstrained imagery

than was previously suspected. We believe this work is the most compre},
 author = {Jones, Michael J. und  Rehg, James M.},
 year = {2002},
 title = {{Statistical Color Models with Application to Skin Detection}},
 pages = {81--96},
 volume = {46},
 number = {1},
 issn = {0920-5691},
 journal = {{International Journal of Computer Vision}},
 doi = {10.1023/A:1013200319198}
}


@book{Kang,
 author = {Kang, Sing Bing und  Szeliski, Richard},
 title = {{Extracting View-Dependent Depth Maps from a Collection of Images}},
 keywords = {Artificial Intelligence (incl. Robotics);Computer Imaging, Vision, Pattern Recognition and Graphics;Image Processing and Computer Vision;Pattern Recognition},
 institution = {{SpringerLink (Online service)}}
}


@incollection{Keskin2012,
 author = {Keskin, Cem und  K{\i}ra{\c{c}}, Furkan und  Kara, Yunus Emre und  Akarun, Lale},
 title = {{Hand Pose Estimation and Hand Shape Classification Using Multi-layered Randomized Decision Forests}},
 pages = {852--863},
 volume = {7577},
 publisher = {Springer},
 isbn = {978-3-642-33782-6},
 series = {{Lecture Notes in Computer Science}},
 editor = {Fitzgibbon, Andrew und  Lazebnik, Svetlana und  Perona, Pietro und  Sato, Yoichi und  Schmid, Cordelia},
 booktitle = {{Computer vision - ECCV 2012}},
 year = {2012},
 address = {Berlin},
 doi = {10.1007/978-3-642-33783-3{\textunderscore }61}
}


@inproceedings{Li2013,
 author = {Li, Cheng und  Kitani, Kris M.},
 title = {{Pixel-Level Hand Detection in Ego-centric Videos}},
 pages = {3570--3577},
 publisher = {IEEE},
 isbn = {978-0-7695-4989-7},
 booktitle = {{IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2013}},
 year = {2013},
 address = {Piscataway, NJ},
 doi = {10.1109/CVPR.2013.458}
}


@inproceedings{Molchanov27.06.201630.06.2016,
 abstract = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR);2016; ; ;10.1109/CVPR.2016.456},
 author = {Molchanov, Pavlo und  Yang, Xiaodong und  Gupta, Shalini und  Kim, Kihwan und  Tyree, Stephen und  Kautz, Jan},
 title = {{Online Detection and Classification of Dynamic Hand Gestures with Recurrent 3D Convolutional Neural Networks}},
 pages = {4207--4215},
 publisher = {IEEE},
 isbn = {978-1-4673-8851-1},
 booktitle = {{2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}},
 year = {27.06.2016 - 30.06.2016},
 doi = {10.1109/CVPR.2016.456}
}


@article{OhnBar2014,
 author = {Ohn-Bar, Eshed und  Trivedi, Mohan Manubhai},
 year = {2014},
 title = {{Hand Gesture Recognition in Real Time for Automotive Interfaces: A Multimodal Vision-Based Approach and Evaluations}},
 pages = {2368--2377},
 volume = {15},
 number = {6},
 issn = {1524-9050},
 journal = {{IEEE Transactions on Intelligent Transportation Systems}},
 doi = {10.1109/TITS.2014.2337331}
}


@inproceedings{Oikonomidis2011,
 author = {Oikonomidis, Iason und  Kyriazis, Nikolaos und  Argyros, Antonis},
 title = {{Efficient model-based 3D tracking of hand articulations using Kinect}},
 pages = {101.1--101.11},
 publisher = {{BMVA Press}},
 isbn = {1-901725-43-X},
 editor = {Hoey, Jesse},
 booktitle = {{Proceedings of the British Machine Vision Conference 2011}},
 year = {2011},
 address = {Durham},
 doi = {10.5244/C.25.101}
}


@incollection{Pfister2015,
 author = {Pfister, Tomas und  Simonyan, Karen und  Charles, James und  Zisserman, Andrew},
 title = {{Deep Convolutional Neural Networks for Efficient Pose Estimation in Gesture Videos}},
 pages = {538--552},
 volume = {9003},
 publisher = {{Springer International Publishing}},
 isbn = {978-3-319-16864-7},
 series = {{Lecture Notes in Computer Science}},
 editor = {Cremers, Daniel und  Reid, Ian und  Saito, Hideo und  Yang, Ming-Hsuan},
 booktitle = {{Computer Vision -- ACCV 2014}},
 year = {2015},
 address = {Cham},
 doi = {10.1007/978-3-319-16865-4{\textunderscore }35}
}


@inproceedings{Poier2015,
 author = {Poier, Georg und  Roditakis, Konstantinos und  Schulter, Samuel und  Michel, Damien und  Bischof, Horst und  Argyros, Antonis A.},
 title = {{Hybrid One-Shot 3D Hand Pose Estimation by Exploiting Uncertainties}},
 pages = {182.1--182.14},
 publisher = {{BMVA Press}},
 isbn = {1-901725-53-7},
 editor = {Xie, Xianghua und  Jones, Mark W. und  Tam, Gary K. L.},
 booktitle = {{Proceedings of the British Machine Vision Conference 2015}},
 year = {2015},
 address = {Durham},
 doi = {10.5244/C.29.182}
}


@inproceedings{Sato1317March2001,
 abstract = {Proceedings IEEE Virtual Reality 2001;2001; ; ;10.1109/VR.2001.913773},
 author = {Sato, Y. und  Saito, M. und  Koike, H.},
 title = {{Real-time input of 3D pose and gestures of a user's hand and its applications for HCI}},
 pages = {79--86},
 publisher = {{IEEE Comput. Soc}},
 isbn = {0-7695-0948-7},
 booktitle = {{Proceedings IEEE Virtual Reality 2001}},
 year = {13-17 March 2001},
 doi = {10.1109/VR.2001.913773}
}


@book{Scharstein,
 author = {Scharstein, Daniel und  Szeliski, Richard},
 title = {{Stereo Matching with Nonlinear Diffusion}},
 keywords = {Artificial Intelligence (incl. Robotics);Computer Imaging, Vision, Pattern Recognition and Graphics;Image Processing and Computer Vision;Pattern Recognition},
 institution = {{SpringerLink (Online service)}}
}


@inproceedings{Sridhar2013,
 author = {Sridhar, Srinath und  Oulasvirta, Antti und  Theobalt, Christian},
 title = {{Interactive Markerless Articulated Hand Motion Tracking using RGB and Depth Data}},
 url = {http://handtracker.mpi-inf.mpg.de/projects/handtracker_iccv2013/},
 booktitle = {{Proceedings of the IEEE International Conference on Computer Vision (ICCV)}},
 year = {2013}
}


@phdthesis{Stark,
 author = {Stark, Michael},
 title = {{On knowledge transfer in object class recognition}},
 type = {{Darmstadt, Techn. Univ., Diss., 2010}}
}


@article{Supancic2018,
 author = {Supan{\v{c}}i{\v{c}}, James Steven und  Rogez, Gr{\'e}gory und  Yang, Yi und  Shotton, Jamie und  Ramanan, Deva},
 year = {2018},
 title = {{Depth-Based Hand Pose Estimation: Methods, Data, and Challenges}},
 pages = {1180--1198},
 volume = {126},
 number = {11},
 issn = {0920-5691},
 journal = {{International Journal of Computer Vision}},
 doi = {10.1007/s11263-018-1081-7}
}


@book{Szeliski1989,
 author = {Szeliski, Richard},
 year = {1989},
 title = {{Bayesian modeling of uncertainty in low-level vision}},
 keywords = {Bayes-Verfahren;Bildverarbeitung},
 isbn = {0792390393},
 series = {{The Kluwer international series in engineering and computer science}}
}


@book{Szeliski2006,
 author = {Szeliski, Richard},
 year = {2006},
 title = {{Image alignment and stitching: A Tutorial}},
 keywords = {Algorithmus;Bildverarbeitung},
 address = {Hanover Mass. u.a.},
 volume = {2,1},
 publisher = {{Now Publ}},
 isbn = {1-933019-04-2},
 series = {{Foundations and trends in computer graphics and vision}}
}


@book{Szeliski2010,
 author = {Szeliski, Richard},
 year = {2010},
 title = {{Computer Vision: Algorithms and Applications}},
 address = {Guildford, Surrey},
 edition = {1. Aufl.},
 publisher = {{Springer London}},
 isbn = {9781848829343},
 series = {{Texts in computer science}}
}


@book{Szeliski2011,
 author = {Szeliski, Richard},
 year = {2011},
 title = {{Computer vision: Algorithms and applications}},
 price = {EUR 80.20},
 keywords = {Bildverarbeitung;Lehrbuch;Maschinelles Sehen},
 isbn = {9781848829343},
 series = {{Texts in computer science}}
}


@book{Szeliski2011b,
 author = {Szeliski, Richard},
 year = {2011},
 title = {{Computer Vision: Algorithms and Applications}},
 address = {London},
 publisher = {{Springer London}},
 isbn = {9781848829350},
 series = {{Texts in computer science}}
}


@inproceedings{Tang2014,
 author = {Tang, Danhang und  Yu, Tsz-Ho und  Kim, Tae-Kyun},
 title = {{Real-Time Articulated Hand Pose Estimation Using Semi-supervised Transductive Regression Forests}},
 pages = {3224--3231},
 publisher = {IEEE},
 isbn = {978-1-4799-2840-8},
 booktitle = {{2013 IEEE International Conference on Computer Vision}},
 year = {2014},
 address = {New York},
 doi = {10.1109/ICCV.2013.400}
}


@article{Tompson2014,
 author = {Tompson, Jonathan und  Stein, Murphy und  Lecun, Yann und  Perlin, Ken},
 year = {2014},
 title = {{Real-Time Continuous Pose Recovery of Human Hands Using Convolutional Networks}},
 pages = {1--10},
 volume = {33},
 number = {5},
 issn = {07300301},
 journal = {{ACM Transactions on Graphics}},
 doi = {10.1145/2629500}
}


@misc{UniFreiburg,
 author = {{Uni Freiburg}},
 title = {{Rendered Handpose Dataset}},
 url = {https://lmb.informatik.uni-freiburg.de/resources/datasets/RenderedHandposeDataset.en.html},
 publisher = {{Uni Freiburg}}
}


@proceedings{Xie2015,
 year = {2015},
 title = {{Proceedings of the British Machine Vision Conference 2015: BMVC 2015, 7-10 September, Swansea, UK}},
 address = {Durham},
 publisher = {{BMVA Press}},
 isbn = {1-901725-53-7},
 editor = {Xie, Xianghua und  Jones, Mark W. und  Tam, Gary K. L.},
 institution = {{British Machine Vision Conference} und  BMVC},
 doi = {10.5244/C.29}
}


@misc{Zhang23.10.2016,
 abstract = {3D hand pose tracking/estimation will be very important in the next generation of human-computer interaction. Most of the currently available algorithms rely on low-cost active depth sensors. However, these sensors can be easily interfered by other active sources and require relatively high power consumption. As a result, they are currently not suitable for outdoor environments and mobile devices. This paper aims at tracking/estimating hand poses using passive stereo which avoids these limitations. A benchmark with 18,000 stereo image pairs and 18,000 depth images captured from different scenarios and the ground-truth 3D positions of palm and finger joints (obtained from the manual label) is thus proposed. This paper demonstrates that the performance of the state-of-the art tracking/estimation algorithms can be maintained with most stereo matching algorithms on the proposed benchmark, as long as the hand segmentation is correct. As a result, a novel stereo-based hand segmentation algor},
 author = {Zhang, Jiawei und  Jiao, Jianbo und  Chen, Mingliang und  Qu, Liangqiong und  Xu, Xiaobin und  Yang, Qingxiong},
 date = {23.10.2016},
 title = {{3D Hand Pose Tracking and Estimation Using Stereo Matching}},
 url = {http://arxiv.org/pdf/1610.07214v1},
 keywords = {Computer Science - Computer Vision and Pattern Recognition}
}


@misc{Zimmermann03.05.2017,
 abstract = {Low-cost consumer depth cameras and deep learning have enabled reasonable 3D hand pose estimation from single depth images. In this paper, we present an approach that estimates 3D hand pose from regular RGB images. This task has far more ambiguities due to the missing depth information. To this end, we propose a deep network that learns a network-implicit 3D articulation prior. Together with detected keypoints in the images, this network yields good estimates of the 3D pose. We introduce a large scale 3D hand pose dataset based on synthetic hand models for training the involved networks. Experiments on a variety of test sets, including one on sign language recognition, demonstrate the feasibility of 3D hand pose estimation on single color images.},
 author = {Zimmermann, Christian und  Brox, Thomas},
 date = {03.05.2017},
 title = {{Learning to Estimate 3D Hand Pose from Single RGB Images}},
 url = {http://arxiv.org/pdf/1705.01389v3},
 keywords = {Algorithms;Algorithmus;Artificial Intelligence (incl. Robotics);Bayes-Verfahren;Bildverarbeitung;Computer Imaging, Vision, Pattern Recognition and Graphics;Computer Science - Computer Vision and Pattern Recognition;Dataset;Gestures;Humans;Image Processing and Computer Vision;Learning;Lehrbuch;Maschinelles Sehen;Neural Networks (Computer);Normal Distribution;Pattern Recognition;Pattern Recognition, Automated}
}


